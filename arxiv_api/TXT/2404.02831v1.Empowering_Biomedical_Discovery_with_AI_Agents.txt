Empowering Biomedical Discovery with AI Agents
ShanghuaGao1,AdaFang1,2,8,+,YepengHuang1,3,+,ValentinaGiunchiglia1,4,+,AyushNoori1,5,+,Jonathan
RichardSchwarz1,YashaEktefaie1,6,JovanaKondic7,andMarinkaZitnik1,8,9,10,#
1DepartmentofBiomedicalInformatics,HarvardMedicalSchool,Boston,MA,USA
2DepartmentofChemistryandChemicalBiology,HarvardUniversity,Cambridge,MA,USA
3PrograminBiologicalandBiomedicalSciences,HarvardMedicalSchool,Boston,MA,USA
4DepartmentofBrainSciences,ImperialCollegeLondon,London,UK
5HarvardCollege,Cambridge,MA,USA
6PrograminBiomedicalInformatics,HarvardMedicalSchool,Boston,MA,USA
7DepartmentofElectricalEngineeringandComputerScience,MIT,Cambridge,MA,USA
8KempnerInstitutefortheStudyofNaturalandArtificialIntelligence,HarvardUniversity,MA,USA
9BroadInstituteofMITandHarvard,Cambridge,MA,USA
10HarvardDataScienceInitiative,Cambridge,MA,USA
+Co-secondauthors
#Correspondence:marinka@hms.harvard.edu
Summary
Weenvision“AIscientists”assystemscapableofskepticallearningandreasoningthatempowerbiomedical
researchthroughcollaborativeagentsthatintegratemachinelearningtoolswithexperimentalplatforms.
Ratherthantakinghumansoutofthediscoveryprocess,biomedicalAIagentscombinehumancreativity
andexpertisewithAI’sabilitytoanalyzelargedatasets,navigatehypothesisspaces,andexecuterepetitive
tasks. AIagentsareproficientinavarietyoftasks,includingself-assessmentandplanningofdiscovery
workflows.Theseagentsuselargelanguagemodelsandgenerativemodelstofeaturestructuredmemoryfor
continuallearningandusemachinelearningtoolstoincorporatescientificknowledge,biologicalprinciples,
andtheories. AIagentscanimpactareasrangingfromhybridcellsimulation,programmablecontrolof
phenotypes,andthedesignofcellularcircuitstothedevelopmentofnewtherapies.
1 Introduction
Along-standingambitionforartificialintelligence(AI)inbiomedicineisthedevelopmentofAIsystemsthat
couldeventuallymakemajorscientificdiscoveries,withthepotentialtobeworthyofaNobelPrize—fulfilling
theNobelTuringChallenge[1]. Whiletheconceptofan“AIscientist”isaspirational,advancesinagent-based
AIpavethewaytothedevelopmentofAI agentsasconversablesystemscapableofskepticallearningand
reasoningthatcoordinatelargelanguagemodels(LLMs),machinelearning(ML)tools,experimentalplatforms,
orevencombinationsofthem[2–5](Figure1).
Thecomplexityofbiologicalproblemsrequiresamultistageapproach,wheredecomposingcomplexquestions
intosimplertasksisnecessary. AIagentscanbreakdownaproblemintomanageablesubtasks,whichcan
then be addressed by agents with specialized functions for targeted problem-solving and integration of
scientificknowledge,pavingthewaytowardafutureinwhichamajorbiomedicaldiscoveryismadesolelyby
AI[2,6]. Inthenearfuture,AIagentscanacceleratediscoveryworkflowsbymakingthemfasterandmore
1
4202
rpA
3
]IA.sc[
1v13820.4042:viXra
resource-efficient. Lookingahead,AIagentscanenableinsightsthatmightnothavebeenpossibleusingML
alonebymakingpredictionsacrosstemporalandspatialscalespriortoexperimentalmeasurementsatthose
scales,andcaneventuallyidentifynewmodesofbehaviorwithinbiologicalsystems[6].
ThisvisionispossiblethankstoadvancesinLLMs[7–9],multimodallearning,andgenerativemodels. Chat-
optimized LLMs, such as GPT-4 [10], can incorporate feedback, enabling AI agents to cooperate through
conversations with each other and with humans [11]. These conversations can involve agents providing
andseekingadvice,critique,andvalidation[12,13]. Then,sinceasingleLLMcanexhibitabroadrangeof
capabilities—especiallywhenconfiguredwithappropriatepromptsandinferencesettings, conversations
betweendifferentlyconfiguredagentscancombinethesecapabilitiesinamodularmanner[14]. LLMshave
alsodemonstratedtheabilitytosolvecomplextasksbybreakingthemintosubtasks[15,16]. However,suppose
wefollowconventionalapproachestofoundationmodelssuchasLLMsandotherlargepre-trainedmodels.
Inthatcase,wemaynotdevelopAIagentsthatcangeneratenovelhypothesesbecausesuchnoveltywould
nothavebeeninthedatausedtotrainthemodel,suggestingthatcurrentfoundationmodelsalonearenot
sufficientfor“AIscientists”. UsingLLMsasacomparison,generatingnovelhypothesesrequirescreativity
andgroundinginscientificknowledge,whereasgeneratingnoveltextrequiresadherencetosemanticand
syntacticrules[17],sothelatterapproachalignswellwithtechniquesfornext-tokenpredictionwithinLLMs,
whiletheformerdoesnot.
Here,weofferaperspectivethat“AIscientists”canberealizedasAIagentsbackedbyhumans,LLMs,ML
models,andothertoolslikeexperimentalplatformsthatcooperatetosolvecomplextasks. AnAIagentshould
beskepticalwhendevelopingbiologicalhypotheses,capableofcharacterizingitsuncertaintyandusingthatas
adrivertoacquireandrefineitsscientificknowledgebasesinawaythathumanscientistpartnerscantrust[18].
AIagentsshouldbedesignedtoadapttonewbiologicalinsights, incorporatethelatestscientificfindings,
andrefinehypothesesbasedonexperimentalresults. Thisadaptabilityensuresagentsremainrelevantinthe
face of rapidly evolving biological data and understanding [17]. However, the challenge lies in developing
algorithmsthatallowforthiscontinuallearningwithoutsufferingfromcatastrophicforgetting[19],which
requiresabalancebetweenacquiringnewknowledgeandretainingexistinginformation. Byaddressingthis
challenge,AIagentscanpowerplatforms,suchasclosed-loopsynthesisframeworks,autonomousmicroscopy
facilities,andhybridcellsimulators.
EthicalconsiderationsarisefromusingAIagents[20,21].AllowingAIagentstomakechangesinenvironments
throughtoolsorcallstoexperimentalplatformscanbedangerous.Safeguardsandprotocolsneedtobeinplace
topreventharmandnegativeoutcomes[22]. Conversely,discoveryworkflowsmightincludeconversations
betweenAIagents(butnointeractionwithenvironmentsisallowed). Inthatcase,weneedtoconsiderthe
impactofsuchinteractionsonscientistsandtheirrelianceonAIagents. TheimpactofAIagentsonbiology,
coupledwiththechallengestheypose,underscorestheneedforresponsibleimplementation. AIagentshave
thepotentialtoperformresearchandoperationaltasksundertheoversightofhumans[2].
2 Evolving use of data-driven models in biomedical research
Data-drivenmodelshavereshapedbiomedicalresearchoverthepastseveraldecadesthroughthedevelopment
ofdatabases,searchengines,machinelearning,andinteractiveandfoundationlearningmodels(Figure2).
Thesemodelshaveadvancedmodelingofproteins[23–27],genes[28],phenotypes[29],clinicaloutcomes[30–
32],andchemicalcompounds[33,34]throughminingofbiomedicaldata.
Databasesandsearchengines. Inbiologicalresearch,databases(DBs) [35–37]aggregateknowledgefrom
experimentsandstudies,offeringsearchablerepositoriescontainingstandardizedbiologicaldatavocabularies.
AnexampleofsuchadatabaseistheAlphaFoldProteinStructureDB[38], whichincludesmorethan200
2
millionproteinstructurespredictedbyAlphaFold[39]. Molecularsearchenginesretrieveinformationfrom
thesedatabases[40–42]. FoldSeek[43]retrievesproteinstructuresfromtheAlphaFoldDBbytranslatingquery
structuresinto3Dinteractionalphabetsequencesandusingpretrainedsubstitutionmatrices.
Distinctfromsearchengines,designedforretrievinginformationbasedonspecificqueries,AIagentsare
capableofreasoningtoformulatesearchqueriesandsubsequentlyacquireinformation.Curateddatabasesoffer
structuredandfactualinformation,aidinginreducingtherisksassociatedwithmisinformationpotentially
generatedbyagenthallucinations[44]. Anotablefeatureoftheseagentsistheirabilitytodynamicallyretrieve
informationwhenneededandtocreateandreflectupontheobtainedpassages.Thisreflectionprocessrenders
theagentcontrollableduringinference,allowingforcustomizationofitsactionstomeettherequirementsof
tasksbeyondwhatispossibleusingsearchenginesanddatabasequeries.
Machine learning models. Beyond information retrieval, ML models excel in identifying patterns and
assimilatinglatentknowledgetogeneralizepredictionsaboutnoveldata[45–47]. AnexampleisAlphaFold[39]
protein folding model that uses multi-sequence alignment with a deep learning model to predict the 3D
proteinstructurefromaminoacidsequences,achievingnear-atomlevelaccuracy. AIagentsrepresentan
evolutioninMLmodels,buildingonthefoundationsofsuccessessuchasthetransformerarchitecture[48]
andgenerativepretraining[9]. Theseagentshavereasoningandinteractivecapabilitiesthatdistinguishthem
fromMLmodels,whichtypicallyrequirespecializedmodelsforeachtask. UnliketraditionalMLmodels,
agentsassesstheevolvingenvironment,whichisvaluableformodelingdynamicbiologicalsystems.
Interactivelearningmodels. Interactivelearning,oftenreferredtoasactivelearning[49]andreinforcement
learning[50],representsafurtheradvancementinMLmodels. Thismethodenhancestheadaptabilityand
efficiencyofMLtechniquesbyincorporatingexplorationandfeedbackmechanisms. Activelearningfocuses
on efficiently training models with limited labeled data, proving particularly advantageous in biological
learningwheredatamaybeinsufficient. Itselectivelyqueriesthemostinformativedatapointsforlabeling
andoptimizingthelearningprocess,whichimproveshowmodelslearnwithdata. Reinforcementlearning
involvesanagentlearninghowtoactbyobservingtheresultsofpastactionsinanenvironment,mirroring
thetrial-and-errorapproach. Inbiologicalresearch,interactivelearninghasbeenappliedtovariousfields,
such as small molecule design [51], protein design [52, 53], drug discovery [54, 55], perturbation experiment
design[56],andcancerscreening[57]. Forinstance,GENTRL[51]usesreinforcementlearningtonavigatethe
chemicalspaceandfindcandidatechemicalcompoundsthatcanactagainstabiologicaltarget.
Leveraginginteractivelearning,AIagentsachievegreaterautonomyininformationretrievaltasks. Active
learningimprovestrainingefficiencythroughdatalabelingselectedtomaximizemodelperformance.However,
AIagentsextendbeyondthisdata-centricapproach;forexample,reinforcementlearningwithhumanfeedback
(RLHF)[50]usesa“rewardmodel”totrainandfine-tuneanLLM-basedagentwithdirecthumanfeedbackto
understandhumaninstructionnaturally.
AIagents. Lookingahead,AIagentshaveadvancedcapabilities,includingproactiveinformationacquisition
throughperceptionmodules,interactionwithtools,reasoning,andthecapabilitytoengagewithandlearn
fromtheirenvironments. Agentsuseexternaltools,suchaslabequipment,andhaveperceptionmodules,
such as integrated visual ML tools to receive information from the environment (Section 5). Agents can
incorporate search engines and ML tools and process information across data modalities via perception
modulestogeneratehypothesesandrefinethembasedonscientificevidence[2,3].
3 Types of biomedical AI agents
TheprevailingapproachtobuildingagentsnowadaysistouseLLMs,whereasingleLLMisprogrammed
toperformvariousroles(Section3.1). However,beyondLLMagents,weenvisionmulti-agentsystemsfor
3
discoveryworkflowsthatcombineheterogeneousagents(Figure1)consistingofMLtools,domain-specific
specializedtools,andhumanexperts(Section3.2). Giventhatmuchofbiomedicalresearchisnottext-based,
suchagentshavebroaderapplicabilitytobiomedicine.
3.1 Large language model based AI agents
ProgrammingasingleLLMwithdiverserolesequipsLLM-basedagentswithconversationalinterfacesthat
emulatehumanexpertiseandcanaccesstools[58,59](Figure3a). Therationalebehindthisapproachstems
frompretraininganLLMtoencodegeneralknowledge,followedbyin-domainfine-tuningoftheLLMto
encodedomain-specificspecialistknowledgeandaligningtheLLMwithhumanusersthroughrole-playing
andconversation. Instructiontuning[60]canbeusedfortheformerbytrainingtheLLMtofollowhuman
instructionthroughtheuseofpromptexamples,includingdialoguesthatincorporatebiologicalreasoning
[61]. Additionally,RLHFoptimizesLLMperformancebyselectingthemosthuman-preferredoutputsfroma
rangeofresponsestospecificprompts,furtheraligningLLMswithhumanroles. Consequently,asingleLLM,
programmed to fulfill multiple roles, can provide a more practical and effective solution than developing
specializedmodels. Byassigningspecificroles,theagentscanreplicatethespecializedknowledgeofexperts
acrossvariousfields,suchasstructuralbiology,genetics,andchemistry,surpassingthecapabilitiesofquerying
anon-specializedLLM[62]andperformingtaskspreviouslynotpossible[63].Earlyresultsinclinicalmedicine
question-answeringsuggestthatassigningspecificrolestoGPT-4[62]canachievebetterperformancethan
usingdomain-specializedLLMslikeBioGPT[64],NYUTron[65],andMed-PaLM[66,67].
We envision three approaches for assigning roles to biological AI agents: domain-specific fine-tuning, in-
contextlearning,andautomaticgenerationofoptimizedroles. Thefirstapproachinvolvesinstruction-tuning
anLLMacrossalargenumberofbiologicaltaskstogroundtheLLMinthebiologicaldomain,followedby
RLHFtoensurethatthetunedLLMperformstasksalignedwiththegoals,wants,andneedsofscientists. The
secondapproachusesin-contextlearningofLLMs[68]toprocesslongercontextualinformationprovided
in inputs, such as biologist-generated instructions, enabling agents to grasp the domain context for each
task. This approach is supported by using textual prompts to define agent roles [63, 69]. Both strategies
requirebiologiststocarefullygathertask-specificdataorcraftprompts. However,asrolesdefinedbyhumans
maynotalwaysdirectagentsasintended,therehasbeenamovementtowardsallowingLLM-basedagents
moreautonomyinrolespecification. Thisparadigmshiftinroledefinitionenablesagentstoautonomously
generate and refine role prompts, engaging in self-directed learning and role identification. For instance,
Fernandoetal.[70]demonstrateanagent’sabilitytoevolveandtailoritspromptsinreactiontouserinputs.
Similarly,Yangetal.[71]investigatetheapplicationofLLMasanoptimizertoenhancepromptrefinementand
optimizationforimprovedperformanceinassignedroles. Throughthisself-referentiallearningframework,
agentstransitionfromtaskexecutorstoentitiescapableofmoreautonomouslearning.
Theagentsystem,comprisingasingleLLMpromptedtoadoptvariousroles,hasproventobeaneffective
auxiliaryinscientificresearch. Studiessuggestthatagentsallocatedspecificrolesexhibitenhancedcapabilities
comparedtoeithersequentiallyqueryingasingleLLMoremployingasingletoolrepetitively. Acaseinpoint
isCoscientist[2],whichshowsthepotentialofGPT-4-basedagentsforchemicalresearchtasks,including
optimizingreactionsforpalladium-catalyzedcross-couplings. WithinCoscientist,GPT-4undertakestherole
ofaplanner,servingasaresearchassistant. Theagentusesin-contextpromptstosupporttheuseoftoolssuch
aswebanddocumentationsearch,codeexecutionviaPythonAPI,andevensymboliclablanguage(SLL)[2].
Tocompletetasksthatrequireaccesstoaphysicaldevice,theplanningagentstartswithapromptprovidedby
thescientistandusessearchtoolstocompilethedocumentationfortheexperiment. Followingthis,theagent
generatesSLLcodeandexecutesit,whichentailstransferringitontothedeviceandcontrollingthedevice.
4
3.2 Multi-agent AI systems
LLM-basedagentsimplementedthroughautoregressiveLLMapproachesacquireskillssuchasplanningand
reasoningbyemulatingobservedbehaviorsintrainingdatasets. However,thismimicry-basedlearningresults
inlimitedagentcapabilities,astheydonotachieveadeepunderstandingofthesebehaviors[72].Consequently,
asingleagentoftenlacksthecomprehensiveskillsetneededtocompletecomplextasks. Apracticalalternative
isdeployingamulti-agentAIsystem,whereinthetaskissegmentedintomoremanageablesubtasks. This
approachallowsindividualagentstoaddressspecificsubtasksefficiently,evenwithincompletecapabilities.
Distinct from single-LLM-based agents, a multi-agent system incorporates several agents endowed with
specializedcapabilities,tools,anddomain-specificknowledge.Forsuccessfultaskexecution,theseagentsmust
conformtoworkingprotocols. SuchcooperativeeffortsequipLLMswithuniqueroles,specializedknowledge
bases,andvariedtoolsets,simulatinganinterdisciplinaryteamofbiologyspecialists. Thisapproachisakinto
thediverseexpertisefoundacrossdepartmentswithinauniversityoraninstitute.
Inthefollowing,weintroducefivecollaborativeschemesformulti-agentsystems.
Brainstormingagents(Figure3b). Brainstormingresearchideaswithmultipleagentsconstitutesacollab-
orativesessiontogenerateabroadspectrumofresearchconceptsthroughthejointexpertiseofscientists
andagents. Insuchsessions,agentsarepromptedtocontributeideas,prioritizingthevolumeofcontribu-
tionsovertheirinitialqualitytofostercreativityandinnovation. Thismethodencouragestheproposalof
unconventionalandnovelideas,allowingparticipantstobuilduponthesuggestionsofotherstouncovernew
avenuesofinquirywhilewithholdingjudgmentorcritique. Theprocessenablesagentstoapplytheirdomain
knowledgeandresourcestoformacollectiveideapool. Thispoolcanthenbedistilledandexaminedmore
thoroughly. Tofosterdivergentthinkingandcreativity,itcanbebeneficialforagentstospecializeinareas
ofbiology,forinstance,microgliabiology,neuronaldegeneration,andneuroinflammationinthecaseofa
multi-agentsystemforAlzheimer’s.
Expertconsultationagents(Figure3c). Expertconsultationentailssolicitingexpertisefromindividuals
or entities with specialized knowledge. This process involves expert agents gathering information from
various sources and providing insights, solutions, decisions, or evaluations in response. Other agents or
humansthenrefinetheirapproachesbasedonthisfeedback. Liangetal.[73]illustratethatLLMscanfunction
like human expert reviewers, offering scientific critiques on research manuscripts. Similarly, an AI agent
mightconsultanotheragentspecializedinaspecificareatorefineideaswithinAIsystems,mirroringthe
mentor-menteedynamicsfoundinacademicenvironments. Inanotherexample,inaddressingAlzheimer’s
andrelateddementias,diagnosingAlzheimer’sbasedoncognitivecriteriamightpresentborderlinecases.
ConsultinganAIagentcouldofferadditionalperspectives,determiningifsuchcasesalignwithAlzheimer’s
basedonbrainpathologyoralternativebiomarkers.
Researchdebateagents(Figure3d). Inaresearchdebate,twoteamsofagentspresentcontrastingperspec-
tivesonaresearchtopic,aimingtopersuadetheagentsoftheopposingteam. Agentsaresplitintotwogroups,
eachadoptingdistinctrolesforthedebate. Onegroupgathersevidencetofortifyitspositionusingvarious
knowledgesourcesandtools,whiletheopposinggroupcritiquesthisevidence,strivingtoexposeorneutralize
itsweaknesseswithsuperiorevidence. Theobjectiveforeachfactionistoarticulatetheirargumentsmore
effectivelythantheirrivals,engaginginasystematicdiscoursetodefendtheirviewpointandchallengethe
veracityoftheiradversaries’assertions. Thismethodologypromotescriticalthinkingandbolsterseffective
communicationaseachteamendeavorstoconstructthemostcompellingargumentsupportingtheirstance.
Roundtablediscussionagents(Figure3e). Round-tablediscussionsinvolvemultipleagentsengagingina
processthatfosterstheexpressionofdiverseviewpointstomakecollaborativedecisionsonthetopicsunder
discussion. Insuchsessions,agentsarticulatetheirideasandinsights,posequestions,andprovidefeedbackon
others’contributions. Theythenrespondtothesequeries,refinetheirinitialpropositionsbasedonfeedback,
5
orattempttopersuadetheirpeers. Thismethodpromotesequalparticipationamongallagents,urgingthem
tocontributetheirexpertiseandperspectives,offerconstructivecriticism,questionunderlyingassumptions,
and suggest amendments to improve the proposed solutions. For instance, Reconcile [74] implements a
collaborativereasoningschemeamongLLMagentsthroughsuccessiveroundsofdialogue. Agentsattemptto
convinceeachothertoadjusttheirresponsesanduseaconfidence-weightedvotingmechanismtoachievea
moreaccurateconsensusthanifasingleLLM-basedagentisused. Duringeachdiscussionround,Reconcile
orchestratestheinteractionbetweenagentsusinga‘discussionprompt,’whichincludesgroupedanswersand
explanationsproducedbyeachagentintheprecedinground,theirconfidencelevels,andexamplesofhuman
explanationsforcorrectinganswers.
Self-drivinglabagents(Figure3f).Theself-drivinglaboratoryisamulti-agentsystemwheretheend-to-end
discoveryworkflowisiterativelyoptimizedunderthebroaddirectionofscientistsbutwithoutrequiring
step-by-stephumanoversight[75]. Oncetheagentsystemistrained,itcandescribeexperimentsnecessaryto
testthegeneratedhypotheses,analyzetheresultsofsaidexperiments,andusethemtoimproveitsinternal
scientificknowledgemodels. Agentsintheself-drivingsystemneedtoaddressthefollowingthreeelements:
determine inductive biases to reduce the search space of hypotheses, implement methods to rank order
hypothesesconsideringtheirpotentialbiomedicalvaluewithexperimentalcost,characterizeskepticismvia
uncertainty quantification and analysis of experiments in reference to the original hypothesis, and refine
hypothesesusingdataandcounterexamplesfromexperiments[76]. Ideally,hypothesisagentsarecreative
andskepticalwhendevelopingbiologicalhypothesesthatextrapolateindirectlyfromtheexistingbodyof
knowledge[17]. Experimentalagentssteeroperationalagentsthatuseacombinationofinsilicoapproaches
andphysicalplatformstoexecuteexperiments. Followingthis,reasoningagentsintegratethelatestresultsto
guidefutureexperimentaldesign. Theutilityofexperimentalresults,suchastheyieldofhigh-throughput
screeningofachemicallibraryagainstabiologicaltarget,canbecomparedfordifferentversionsoftheagent
systemgivenatimebudgetforhypothesisandexperimentgeneration.
4 Levels of autonomy in AI agents
AIagents,whenintegratedwithexperimentalplatforms,canoperateatvaryinglevelsofautonomytailored
tothediverserequirementsacrossbiomedicalfields. WeclassifytheseAIagentsintofourlevelsaccording
totheirproficiencyinthreeareasofdiscovery: Hypothesis,Experiment,andReasoning(Table1). Specific
capabilitieswithineachareadefinetheselevels,necessitatingthatagentsexhibitthecapabilitiesforagiven
levelacrossallareas(anagentwithLevel3capabilitiesintheExperimentareabutonlyLevel2capabilitiesin
ReasoningandHypothesisareaswouldbeclassifiedasLevel2).
Level0,denotedasnoAIagent,usingMLmodelsastools. Thislevelalignswiththeprevailingapproachof
usinginteractiveandfoundationlearningmodels(Section2). Atthislevel,MLmodelsdonotindependently
formulatetestableandfalsifiablestatements[77]ashypotheses. Instead,modeloutputshelpscientiststoform
precisehypotheses. Forexample,astudyemployedAlphaFold-MultimertopredictinteractionsofDONSON,
aproteinwithlimitedunderstanding,leadingtoahypothesisaboutitsfunctions[78]. Level1,termedAIagent
asaresearchassistant,featuresscientistssettinghypotheses,specifyingnecessarytaskstoachieveobjectives,
andassigningspecificfunctionstoagents. Theseagentsworkwitharestrictedrangeoftoolsandmulti-modal
datatoexecutethesetasks. Forinstance,ChemCrow[3]combineschain-of-thoughtreasoning[79]withML
toolstosupporttasksinorganicchemistry,identifyingandsummarizingliteraturetoinformexperiments.
Inanotherexample,AutoBa[80]automatesmulti-omicanalyses. Thesetwoagentsaredesignedfornarrow
scientificdomains;ChemCrowandAutoBaoptimizeandexecuteactionstocompletetasksthataredesigned
and predefined by scientists. Level 1 agents [3, 80–82] formulate simple hypotheses inferred from existing
knowledgeandutilizealimitedsetoftools,lackingthecapacityforamajorscientificdiscoverynecessaryto
6
achieveLevel2autonomy.
AtLevel2,AIagentasacollaborator,theroleofAIexpandsasscientistsandagentscollaborativelyrefine
hypotheses. Agentsundertaketaskscriticalforhypothesistesting,usingawiderarrayofMLandexperimental
tools for scientific discovery. However, their capability to understand scientific phenomena and generate
innovative hypotheses remains constrained, highlighting a linear progression from existing studies. The
transitiontoLevel3,orAIagentasascientist,marksamajorevolution,withagentscapableofdeveloping
andextrapolatinghypothesesbeyondthescopeofpriorresearch,synthesizingconceptsbeyondsummarizing
findings,andestablishingconcise,informativeandclearconceptuallinksbetweenfindingsthatcannotbe
inferred from literature alone, eventually yielding a new scientific understanding. While multiple Level 1
agentsexistacrossvariousscientificfields,Levels2and3agentshaveyettoberealized.
Thelevelsofautonomydescribedforartificialgeneralintelligence(AGI)agentsinscientificcontexts,particu-
larlyinbiology,deviatefromexistingtaxonomiesthatfocusongeneralhuman-AIinteractionseparatefrom
thecollaborativedynamicsbetweenscientistsandAI.Existingtaxonomiesofautonomyconsidersolelythebal-
anceofresponsibilitiesbetweenAIagentsandhumans—withnoconsiderationofbiomedicaldiscovery—and
focusondevelopingAGItosurpasshumanperformanceacrossvaryingskilllevels[83].
Asthelevelofautonomyincreases,sodoesthepotentialformisuseandtheriskofscientistsdevelopingan
overrelianceonagents. Whileagentshavethepotentialtoenhancescientificintegrity,thereareconcerns
regardingtheiruseinidentifyinghazardoussubstancesorcontrolledsubstances[84].Responsibledevelopment
ofagentsrequiresdevelopingpreventivemeasures;furtherdiscussiononrisksisin[85,86]andSection6. The
responsibledeploymentofagentsmustaccountfortheriskofoverreliance,particularlyinlightofevidence
thatLLMscanproduceconvincingbutmisleadingclaimsandspreadmisinformation. Theriskswilllikely
increaseasagents undertake moreautonomousresearch activities. Agentsmustbesubjectedto thesame
scrutinyasscientists,includingreproducibilityandrigorouspeerreviewofagenticresearch.
4.1 Illustration of AI agents in genetics
Research in human genetics seeks to understand the impact of DNA sequence variation on human traits.
LLM-basedagentsoperatingatLevel1wouldperformspecifictasksrelevanttogeneticstudies. Forinstance,
inagenome-wideassociationstudy(GWAS),aLevel1agentcanwritebioinformaticscodetoprocessraw
genotypedatato(1)executequalitycontrolmeasures,suchastheremovalofsingle-nucleotidepolymorphisms
(SNPs)missinginmanyindividualsorcontrolforpopulationstratification[87], (2)estimateungenotyped
SNPsthroughimputation,and(3)conducttheappropriatestatisticalanalysestoidentifyrelevantSNPs,taking
intoaccountthefalsediscoveryrate[88]. Followingtheanalysis,theLevel1agentreviewsandreportsfindings,
includinganyfilteredSNPsandrationalesfortheirexclusion.
Insteadofexecutingnarrowtasksfollowinghumaninstruction,aLevel2agentidentifiesandthenexecutes
tasksonitsowninordertorefineahypothesisinitiallygivenbythescientist. Forexample,itmayexplore
theeffectivenessofdrugsforapatientsubgroupwithincomplexdiseases,wheregeneticunderpinningscan
influence drug response [89]. Given a hypothesis that a particular drug is effective in a subset of patients
withidiopathicorgeneticgeneralizedepilepsy(GGE)—aconditionwitharobustgeneticcausality[90]—a
Level2agentwouldsynthesizegeneticinformationfromGWASmeta-analyses[91],suchastheUKBiobank
[92], targeted sequencing studies [93], and knowledge bases like Genes4Epilepsy [94]. The agent identifies
GGEsubtypesandcausalgenesbyanalyzingpatientgeneticdata,predictingwhichsubgroupsmightbenefit
fromthedrugbasedongeneticmarkers. Itwouldthenconductinvitrofunctionalstudiestoconfirmthese
predictions,ultimatelypresentingevidenceonhowthedrugcouldbenefitGGEpatientsubpopulationsby
synthesizingconceptsbeyondsummarizingfindings.
7
Level 3 agents coordinate a system of agents (Figure 3) to discover and evaluate gene markers for specific
phenotypes.Theseagentshelpinitiatenewstudygroupsandoptimizenon-invasivemethodsofDNAcollection
forcost-effectivenessandrecruitmentprocesses[95]. Oncedataarecollected,theagentsinnovatestatistical
methodstoidentifycausalvariantsfromgenotypicdataamidstconfounderssuchaslinkagedisequilibrium
[96]anddevelopinvitrotechniquesforvalidatingcandidategenemarkersindiseasemodels. Level3agents
collaboratewithscientiststogenerateandtesthypothesesforcomprehensivegeneticinsights.
4.2 Illustration of AI agents in cell biology
Cellsarefundamentalunitsofstudyincellbiology.Advancesinsingle-cellomics,super-resolutionmicroscopy,
andgeneeditinghavegenerateddatasetsonnormalandperturbedcells,coveringareassuchasmulti-omics[97–
99], cell viability [100], morphology [101, 102], cryo-electron microscopy and tomography [103, 104], and
multiplexed spatial proteomics [105, 106]. This proliferation of data has spurred interest in in silico cell
modeling [107] with the overall goal of identifying new mechanistic understanding and adaptive cellular
function.
MLtoolshavebeeninstrumentalinanalyzingdataacrossthesecellularmodalities,albeitasLevel0agents
these tools lack autonomous research capabilities. At Level 1, agents integrate specialized Level 0 models
designedfornarrowtaskssuchascelltypeannotationtoassistinhypothesistestingandansweringscientific
questions. Theseagentsactivelyengageinresearch,synthesizingliteratureandpredictingcellularresponses
usingintegratedmodels. Forexample,toinvestigateanewcompound’smechanismofaction(MoA)[99],a
Level 1 agent predicts its effects in various cellular contexts [108]. These predictions inform experimental
design,suchastranscriptomicandproteomicscreening. Theagentalsoretrievesandrefinesexperimental
protocolsforexecutiononplatforms[109]. Afterdatageneration,theagentappliespredefinedbioinformatics
pipelinestoextractinformationfrommulti-modaldatabeforescientistsinterprettheresults.
Level 2 agents not only execute predefined tasks but also generate hypotheses on cellular functions and
compound mechanisms. They autonomously refine tasks to support scientific reasoning, enabling more
efficientexplorationofcomplexphenotypeslikedrugresistancethroughcombinatorialperturbations[110].
Bymanagingtheexperimentalcycleandcontinuouslyupdatingtheirinsilicotools,Level2agentsaimto
minimizeexperimentalredundancyandfocusonkeyvariablesofresistance. However,efficientprobingof
the intractable combinatorial space of genes and contexts is still a considerable challenge. In light of this,
level2agentswouldproposeandoptimizeexperimentsforacomprehensiveyetcost-effectiveevaluationof
hypothesesthroughknowledgebases,managingtheentireexperimentalcyclefromprotocolretrievaland
improvementtoexecution,basedoniterativefeedbackfromscientists[56]. Automaticdataanalysisoccursat
everyexperimentalstage,withtheagentrefininghypotheses,adjustingplans,andcontinuouslyupdatingits
MLtoolsbasedonasynthesisofpredictivecontent,uncertainty,andnewlyacquireddata.
Level3agentsystemswillimplementhybridcellmodelsasdigital-experimentalsimulatorsofcellularresponses
toanytypeofperturbation. AgentsinthehybridcellmodelsystemcombineAItools(digitalagents)with
high-throughputplatforms(experimentalagents). Digitalagents,suchasLLM-basedagents,autonomously
identify knowledge gaps through literature synthesis and handle any perturbagen (extrinsic events such
as gene knockouts, compounds, cell-cell interactions; intrinsic events such as cell cycle) based on criteria
suchasdatavolume,biologicalrelevance,andclinicalneeds. Experimentalagentsgeneratehigh-throughput
transcriptomics [111] and proteomics measurements [112, 113] with a spatial resolution for perturbations,
perturbationscreensincludinginvivosequencing,andmassspectrometryplatforms[113],aswellasbarcoded
spatialproteomics[112,114]. Optimizationofexperimentalprotocols[101,115,116]shiftstheroleofscientists
fromperformingminuteoperationaltaskstomanaginghybridcellmodels.
8
4.3 Illustration of AI agents in chemical biology
Amajorfocusofchemicalbiologyscientistsisonmolecularinteractionswithincellstomanipulatebiological
systemsatmolecularandcellularlevels. AnidealAIagentwouldbeabletoanalyzeanymolecularinteraction,
helpdesignnewdrugs,andprovidemorevaluablechemicalprobesforbiologicalsystems.
DespiteconsiderableadvancesinapplyingMLtochemicalbiology,progresstowardanAIagentproficient
inthescientificmethodwithinthisfieldremainslimited. Existingpredictivemodelsforproteinstructure
prediction [39], molecular docking [117], and generative models for protein design [118, 119] are ML tools
thatcanbewrappedwithinagentsthrough‘functioncalling’andAPIs(Section5.2). Suchagentswouldbe
categorizedasLevel0,whereascientistoverseesallactivities. ALevel1agent,capableofstudyingaspecific
proteintarget,integratesMLtools,suchasAlphaFoldforstructureprediction[39]andneuralnetworksfor
screeningchemicallibraries[120]tofindcandidatechemicalcompoundsthatmightbindthetarget. Thisagent
wouldpossesselementaryreasoningabilitiesbyprobingrelevantliteratureanddesigningexperimentswithin
aspecificdomain[2],althoughitwouldrequirehumanguidanceforcomplexinquiriesanderrorcorrection.
Thescientistwillneedtoguidetheagenttoassistwithmorecomplexquestionsandforerrorchecking. For
example,aLevel1agenttaskedwithbinderdesignforawell-knowntargetwoulddesignverysimilardrug
derivativestoexistingbinders,forwhichthescientistwouldhavetoguidetheagentwithmanydifferentdrug
scaffolds. However,foramorechallengingtarget,itwouldprovidenonsensicalbinders.
ALevel2agentwouldsurpassLevel1byidentifyingnovelresearchavenues,suchasdesigningnewbindersby
leveragingtrendsinrelatedtargets;amethoddemonstratedinmaterialssciencefordiscoveringnewmaterials
[121]. Thisagentwouldemployadvancedreasoningextractingliteraturewithmoreabstractconnectionsto
theresearchtask,suchasidentifyingscaffoldsthatbindtosimilarpocketsandadaptingthemforthetarget. In
addition,theagenthasbroadercapabilitiesinplanninganddesigningexperimentsthanaLevel1agentwith
expertiseinmoredomainssuchasretro-synthesis,crystallography,bioassays,anddirectingroboticarms
toexecutetheseexperiments. Itcanalsoreasonfromtheexperiments’resultstoidentifynoveldiscoveries
andproposefollow-upexperiments. Thus,theagentdemonstratesamorerobustunderstandingofchemical
biologyacrosshypotheses,experiments,andreasoning. Thescientistcollaborateswiththeagentbyproviding
feedbackonthequalityofdesignedinhibitorsandguidingtheagent’sdecisions.
ALevel3agentiscapableofstudyingalltypesofmolecularinteractionsinacell. Thisagentwouldwork
alongside human scientists to explore research questions, proposing de novo binders for an undruggable
target[122]orapoorlystudiedtarget. UnliketheLevel2agent’suseofwell-establishedprotocols,aLevel
3agentunlocksexperimentalcapabilitiesatspatialandtemporalscalesthatarenotcurrentlyaccessibleto
experimentation,ordesignofinsituexperimentstostudymolecularinteractions. Wecanenvisiontheagent
proposing candidate molecules, synthesizing moleculeswith more complex pathways, and designing and
executingassaystotestefficacy. Finally,itcontextualizesresultswithliteraturetounderstandwhatchemical
interactionswouldoccurandwhytheywouldbeprevalent.
5 Roadmap for building AI agents
AI agents can be obtained through LLM-based systems augmented with different modules [4, 58, 59] that
implementfunctionalitiesandaccomplishtasksdetailedinSections3and4. Here,wedescribethesemodules
(Figure 4), focusing on perception, interaction, memory, and reasoning that are necessary for AI agents
to engage with human and experimental environments and to make decisions. Interactions between an
agent and its environment are characterized by two elements: the agent’s perception of its surroundings
anditssubsequentengagementwiththem. Perceptionmodulesenabletheagenttointerpretandassimilate
information from various data modalities. Then, learning and memory allow agents to interact with an
9
environmentandcompletetasks,byacquiringnewknowledgeandretrievingpreviouslylearnedone. Finally,
Reasoningmodulesprocessinformationandexecuteactionplans. Figure5eillustratesanagentsystemthat
usesperception,interaction,memory,andreasoningmodulesforresearchincellbiology[123].
5.1 Perception modules
PerceptionmodulesequipLLM-basedagentswiththecapabilitytounderstandandinteractwithelementsin
theenvironmentinwhichtheyoperate,suchasbiologicalworkflowsandhumanusers. Forperception,agents
need to integrate abilities to receive feedback from multiple sources: scientists [50], the environment [63],
and other AI agents [14, 124]. This requires accommodating a diverse array of modalities. These include:
text descriptions [7]; images from light and (cryo-)electron microscopy to assess cellular processes across
manyconditionssimultaneously[103,104,125];videosfromliveimagingtoassessdevelopmentalprocessesor
animalbehaviorsacrosstime[126–128];longitudinalbiosensorreadoutsandgenomicsprofilesofcells[129];
massspectrometry-basedproteomicstodecipherproteinhomeostasis[25,130];andminiaturizedplatforms
for conducting biochemical assays and 3D culture systems that mimic the physiological context of organ
systems[109].
AIagentscantakedifferentapproachestointeractingwithenvironments. Themostdirectoneinvolvesusing
naturallanguage,whichrepresentsacommonperceptionmodalityforLLM-basedagents. Othertechniques
involveusingmulti-modalperceptionmodules,whereagentsprocessmulti-modaldatastreamsfromthe
environmentoralignmulti-modalinputswithtext-basedLLMs.
Conversationalmodules. WiththeriseofChatGPT,theabilityofAIagentstointerpretnaturallanguage
hasreachedsuchahighlevel[50]thatitisnowpossibletobuildinterfacestoagentsystemsthatareentirely
basedonnaturallanguagewithlimitedmisinterpretations. Themainfocusischatinterfacesthatpreserve
conversationalhistoryinascrollingwindow,whereuserscanconversewithagentsinamannerthatresembles
thestandardapproachofwrittenhuman-to-humaninteraction. Thisapproachallowsscientiststoexpress
theirqueriesusingtheirlanguage,promotinginitiativeandenablingthemtopreciselydescribewhatthey
want. Weenvisionthatagentswillmaintainahistoryofinteractionwithscientistsusingnaturallanguage,
which, in turn, will allow us to keep track of scientific interactions with agents [63, 69]. Combining the
historytraceoftheseinteractionswithretrieval-augmentedgeneration(RAG),itwillbepossibletodevelop
personalizeddiscoveryworkflowstailoredtoindividualscientists.
Multi-modalperceptionmodules. AgentsalignLLMswithotherdatatypestoconsiderdatamodalities
beyondnaturallanguage. Thisapproachhelpsagentsbettermodelthechangingenvironmentinwhichthe
agentactsanddynamicallyadjustitsoutputstonewsituations,suchasevolvedbiologicalstatesinavirtualcell
model. Thealignmentprocessinvolvestwomainstrategies: textualtranslationandrepresentationalignment.
Textualtranslationconvertsinputsintoatextualformat,suchastransformingdatafromroboticsintotextual
descriptionsthatlogenvironmentalstates[10]. Alternatively,throughrepresentationalignment,datafrom
differentmodalitiesareanalyzedbymodality-specificmodelstogeneraterepresentations,suchasusingthe
visual encoder from CLIP [131] for visual information processing. These representations are then aligned
withLLMtextualrepresentations[125,132–135]throughinstructiontuning[125],enablingagentspoweredby
LLMstoperceiveandinterpretmulti-modaldata. Analternativetoalignmentinvolvesallowingtheagentsto
receiveinputexpressedindifferentmodalities[8,136].Forinstance,Fuyu[136]usesadecoder-onlytransformer
architecturetoprocessimagepatchesandtexttokensjointly. Similarly,Gemini[8]isengineeredtohandle
visual,audio,andtextinputswithinasinglemodel. Onceperceptionmodulesareimplementedforagentsto
receiveinputsfromtheenvironment,modulesforinteraction(Section5.2)andreasoning(Section5.4)follow
toprocesstheinputsandinteractexternally.
10
5.2 Interaction modules
Beyond conversational modules, in biological research, scientists use ML-based and other tools, explore
datasets through graphical user interfaces (GUIs) to analyze and visualize data, and engage with physical
equipmentandwetlabexperimentalplatforms. Chat-optimizedLLM-basedagentsthusneedinteraction
capabilitiestocommunicateandcollaboratewithscientists,otherAIagents,andtoolstofunctionbeyond
a simple chatbot. Agents must incorporate essential interaction modules to interact with elements in the
environment.Theseincludeagent-humaninteractiontosupportcommunicationwithscientistsandfollowing
humaninstruction[137,138],multi-agentinteractionforcollaborationamongagents,andtool-useactionto
accessMLtoolsandexperimentalplatforms.
TheseinteractionabilitiesofLLMs,whencombinedwithinteractive‘functioncalling’(i.e.,LLMrequesting
fortaskstobecompleted),canactasanintermediarybetweenscientistsandtheagent’sinterface,aswellas
betweenscientistsandvariousfunctionalitems(e.g.,tools,otheragents,humans). Thisallowsscientistsnotto
searchwhereandhowtoaccomplishtasksbuttosimplyexpresstheirintentionsintheirlanguage. Atthe
sametime,theadvantagesoffunctionalitemsarefullypreservedbecauseagentscaninteractwithtoolsand
usethemtoprovidefeedback.
Agent-humaninteractionmodules.TheinteractionbetweenscientistsandAIagentssynchronizesscientific
objectiveswithAIagentsthroughcooperativecommunicationandmodelingofbiologicalknowledge. Natural
language processing and human evaluation methods are predominantly used to develop this interaction
capability. InstructGPT[50]enhancestheGPTmodelthroughsupervisedfine-tuningwithexamplesofhuman
dialoguestoimprovethemodel’sconversationalskills. Thealignmentbetweenagentsandhumanscanbe
refinedthroughRLHF,whichadjuststhemodelbasedonarewardmodeltrainedusinghumanassessmentsof
themodel’sresponses. Alternatively,RLHFcanbereplacedbydirectpreferenceoptimization[139],whichis
aparameterizedmethodthatprovidesamoreconsistentandefficientalignmentwithhumanpreferences.
Throughagent-humaninteraction,agentsbecomeattunedtohumanneedsandpreferences[11,138],using
humaninsightasadirectiveforcarryingoutcomplextasks[14]. Forinstance,InnerMonologue[138]employs
human feedback to discern user preferences or interpret ambiguous requests in an embodied context. In
AutoGPT [11], humans formulate tasks and score solutions returned by agents, and AutoGen [14] can use
humanexpertisetosolvetasksbetterthanagentsalone.
Multi-agent interaction. Multi-agent interactions support solving complex goals that agents could not
completeiftheyoperatedindependentlyofeachother. Insuchinterdisciplinarysystems,agentsthatcould
specializeindifferentbiologicaldomains,eachwithdistinctcapabilities,engageininteractionsthroughvarious
communication means. Language has emerged as the predominant medium for multi-agent interactions
due to the ability of agents to communicate with humans linguistically [5, 14, 74, 124, 140]. An instance of
thisisGenerativeagents[63],whichcreateinteractiveenvironmentswhereagentsmimichumanbehavior
and interact using natural language. Different strategies are used for multi-agent interaction, including
cooperation[141–143]andnegotiation[74,144,145].Forexample,MetaGPT[142]appliesstandardizedoperating
proceduresfromhumanteamworktodefinetasksandagentresponsibilities.
Throughtheseapproaches,agentinteractionsmakeitpossibletotackletasksthataretoocomplexforjust
oneagenttohandle[81,146]. MedAgent[81]leveragestheexpertiseofmultiplemedicalAIagentsformedical
reasoning. Similarly,RoCo[146]employsrobotagentswithvariedrolestoaccomplishcomplextasksinthe
physicalworld. Multi-agentinteractioncanalsoboosttheproficiencyoflessskilledagentsbyallowingthem
tolearnfrommoreexperiencedcounterparts[147]. Theseinteractionsalsoenablethecreationofsimulations
foravarietyofenvironments,rangingfrompublichealthscenarios[148]tohumansocialbehaviors[63,149],
enhancingthesystem’sadaptabilityandapplicationindiversecontexts.
Tooluse. Tomanagetasksfromdiverseenvironments,agentsrequiretoolstoboosttheircapabilities[150].
11
CommonlyusedtoolsareapplicationAPIs[151],searchengines[152],MLmodels[153],knowledgedatabases[154],
androboticmachineryforphysicaltasks[10,155,156]. DifferentLevel1agentsystemshavebeendeveloped
thatcaninteractwithoneormoretypesoftools. ChemCrow[3]leverageschemicaltoolsandsearchengines
toaddresschemicalchallenges. WebGPT[152]canconductsearchesandnavigatewebbrowsingenvironments.
SayCan[156]controlsarobotinthephysicalworldusinganLLMtocompletetasks. Toinvokethesetools,AI
agentsgeneratecommandsinspecificformats[151,153,154]orquerypre-trainedcontrolmodelstoexecute
actions[156,157]. Todevelopthesecapabilities,agentscanusein-contextlearning[153]orfine-tuningwith
tool-usedemonstrations[151],wherethelatterrepresentsamoresophisticatedapproach.
Inthecaseofin-contextlearning,itisnecessarytoincludesystemabilitiesinthepromptsoagentsystems
can use ‘function calling’ to query tools. For example, HuggingGPT [153] uses ChatGPT as a controller to
integrateallMLmodelsonHuggingFacethroughin-contextlearning. Thealternativeapproachconsistsof
usingmodelfine-tuningwith‘functioncalling’tocreateanLLM-basedagentwithintegratedabilitiesofa
function/tool. Forinstance,Toolformer[151]introducesaself-supervisedlearningmethodtomastertheuse
oftools’APIswithminimaldemonstrationsforeachAPI.
Bymodelingscientists’needsbyanalyzingnaturallanguagetextualinputs,AIagentscanselectthemostlikely
available tool, identify the desired user interface component, and execute the scientist’s expected actions.
Interactionmodulesaredesignedtobeintegratedandadaptedtosuitchangingenvironments. ForLevel2and
Level3agents,agentsautonomouslylearnnewtypesofinteractionsandhow/whentostartusingnewtools.
5.3 Memory and learning modules
WhenusingtoolsandMLmodelsforbiologicalresearch,scientistskeeprecordsofexperimentallogsandplan
theirnextstepsbasedonthem. InAIagents,memorymodulesalleviatetheneedformanuallogrecordingby
memorizingnecessaryexperimentaloutputs. ContrarytoMLmodelsthatperformone-timeinferenceto
generatepredictions,memorymodulesinLLM-basedagentsstoreandrecallinformation. Thisisnecessary
forexecutingcomplextasksandadaptingtoneworevolvingenvironments. Memorymodulesaredesigned
tostorelong-termandshort-termlearnedknowledge. Asagentsencounternewsituationsandacquiredata,
memorymodulesgetupdatedwithnewinformation.
Long-termmemorymodules. Long-termmemorystoresessentialandfactualknowledgethatunderpins
agentbehaviorandunderstandingoftheworld,ensuringthisinformationpersistsbeyondtaskcompletion.
Thismemorycanbeinternal,encodedwithinthemodel’sweightsvialearningprocesses[9,158],orexternal,
maintainedinauxiliaryknowledgebases[159,160]. Internalmemoryisdirectlyusedforaccomplishingzero-
shottasks[7,8]whileaccessingexternalmemoryrequiresactionsbytheagenttofetchandintegratedata
intoshort-termmemoryforimmediateuse[161,162]. Forinstance,ChatDB[154]usesanexternaldatabasefor
memorystorage,andMemoryBank[163]encodesmemorysegmentsintoembeddingsforlaterretrieval.Agents
canqueryknowledgebanks,suchasaGWASdatabasetofindgeneticevidenceforacandidateproteintarget,a
knowledgebaseoftherapeuticmechanismsofaction,andscientificliteraturewithup-to-dateinformationfor
theagenttointegrateanddecidewhethertheproteincanbemodulatedthroughatherapeuticperturbation
(Figure5b). Thelearningprocessupdateslong-termmemorybyaddingnewknowledgeorreplacingoutdated
information. Internal memory of an agent can be updated using parameter-efficient fine-tuning [158, 164],
interactivelearning[50],andmodelediting[165]. Thesestrategiesmustbeeffectiveforlargemodels[164]and
avoidthelossofpreviouslylearnedinformation[166]. Ontheotherhand,updatingexternalmemoryismore
straightforward, involvingmodificationstotheknowledgebase[154,163]. Forexample, indrugdiscovery,
updatinglong-termmemorybyaddinganewcompoundindevelopmenttothedrugbankisaconvenient
waytomaintainanup-to-dateagent.
Short-termmemorymodules. AIagentsuseshort-termmemorytotemporarilystoreinformationduring
12
theirinteractions.Thisshort-termmemoryisenabledthroughin-contextlearning,whererelevantinformation
isintegratedascontextprompts[156,167]orvialatentembeddings[125,132]inLLMs. Forchatbots,previous
conversations are kept as text prompts, supporting multiple rounds of dialogue [50, 168]. The text-based
approachlaysthegroundworkforcommunicationinmulti-agent[74,145]andagent-humanscenarios[11,14].
InembodiedAIagents,environmentalfeedback[156,167]iscapturedintextualformat,actingasashort-term
memorythataidsreasoning. Followingperception,multi-modalinputsareconvertedintolatentembeddings,
which function as short-term memory. LLaVA [125] uses latent embeddings generated by visual encoders
toretainvisualinformation. Short-termmemoryallowsagentstotemporarilyacquireskills,suchastool
usage [151, 153], store information about recent states of a biological system [167, 168], and keep track of
outcomesfromearlierreasoningefforts[12]. Thislearningmechanismiscrucialforagentstolearnandapply
newknowledgeundernewconditions. Moreover,short-termmemorycantemporarilyoverridelong-term
memory,allowingagentstoprecederecentinformationoverolderknowledgewithintheirmodelweights[169].
Agentscanbeinformedbypastexperiencesstoredintheirshort-termmemorytotellwhichexperimentsto
runinthefuture. InFigure5a,wedetailanexamplewheretheagentrecallsexperimentsforahomologous
proteintoinformtheinitialinhibitordesignforthegivenprotein.
5.4 Reasoning modules
Biologicalresearchinvolvesamultidisciplinaryandmultistageprocessthatintegratestheexpertiseofscientists
fromvariousdisciplines. Thesescientistsformulatehypotheses,designexperimentalsetupsbasedonthese
hypotheses, interpret the results, and plan the next steps. Central to this process is human reasoning, an
abilitythatconventionalMLmodelsfindchallengingtoreplicate. Theintegrationofreasoningcapabilities
inAIagentsholdsthepotentialtoexpeditebiologicalresearchbyassistinginseveralofthesecriticalsteps.
Reasoningimprovesagents’capabilitiestoplanexperiments,makedecisionsonbiologicalhypotheses,and
re-solvecompetingcandidatebiologicalmechanisms. Reasoningmodulescanbeimplementedusingdirect
prompting[170]andfew-shotin-contextlearning[79]. Additionally,agentscanuseplannermodels[171,172]
andactionmodels[167]. Weclassifyreasoningmodulesintotwocategories: directreasoningandreasoning
withfeedback. Theclassificationdependsonwhethertheagentadjustsitsplaninresponsetoexperimentalor
humanfeedback.
Directreasoningmodules. Indirectreasoning,anagentperformsplanningandreasoningbasedonthe
current state of the environment, which can follow different reasoning patterns, such as single-path and
multi-pathreasoning. Single-pathreasoninginvolvestheagentbreakingdownthetaskintomultiplerecursive
steps [173]. For instance, chain-of-thought (CoT) reasoning allows agents to reason step-by-step either by
usingin-contextexamples[79]orbyapplyingazero-shotpromptlike"Let’sthinkstep-by-step”[170]. Leap-
of-thought[174]encouragesthemodeltousecreativeratherthanlogicalreasoning. Althoughsingle-path
reasoningmatcheswellwithcertainsituations[175],itsabilitytoadjusttodifferentconditionsislimited.
Conversely,multi-pathreasoningexaminesseveralpathsbeforeconsolidatingthemintoafinalplan[176,177],
allowing for a more thorough planning process that accounts for different scenarios. For example, Least-
to-Mostprompting[178]breaksdowntasksintosubproblemssolvedsequentially. Self-consistentCoT[179]
choosesthemostconsistentanswerfromasetofCoTanswers. Tree-of-thoughts[176]extendsreasoning
pathsintoatree-likestructure,generatingmultiplepathsfromeachthoughtnodeandusingsearchalgorithms
toselectthefinalpath. Graph-of-thoughts[180]furtherdevelopsreasoningpathsintoagraphstructurefor
complexreasoning. Toidentifytheoptimalpath,methodssuchasvotingstrategies[179],MonteCarlotree
search[181],andbreadth/depth-firstsearchalgorithms[176]areused. Throughdirectreasoning,agentscan
generatemultiplethreadsofthoughtthatcouldconsiderthebestpathways,proteintargets,andexperiments
thatcanberuntotesttheroleofacandidateproteintarget(Figure5c).
13
Reasoningwithfeedback. ExperimentalandhumanfeedbackcanhelpAIagentstoimprovereasoning
and planning processes [12, 69, 161]. This feedback may include agent-human interaction (Section 5.2) and
responses from agents, which canbe complementary biologicalassaysquantifying downstream effects of
target molecules [182]. In each reasoning cycle, React [12] incorporates insights from previous actions to
refineitsthoughtprocessandinformfutureactions. LLM-Planner[183]dynamicallyadjustsplansbasedon
newobservationsinanembodiedenvironment. InnerMonologue[138]usesbothpassiveandactivescene
descriptionsandfeedbackfromrecentactionstoguidefutureactions. Voyager[69]improvesplanningfor
subsequentstepsbyconsideringenvironmentfeedback,executionerrors,andself-verification.
Beyond external feedback, an agent’s feedback mechanism enables self-assessing the initial plan [182, 184].
Techniques like self-refine [182] revise action outputs based on the LLM evaluation, the self-check [182]
mechanismallowstheagenttoreviewandadjustitsreasoning,andreflection[13]mechanismsuseprompt
agents to update their decision-making. These techniques incorporate feedback from biologists, such as
exploringexperimentalmethodsandenvironmentalconstraintslikelabinventory(Figure5d).
6 Challenges
TheperspectiveoutlineskeystepstoimplementAIagentsinbiomedicalresearchandhighlightsareasthatcan
benefitfromagenticAI.Challengesremainandmay,insomecases,beamplifiedwhenmulti-agentsystems
becomeavailable. Belowaretechnicalobstaclesandchallengestoovercome(Figure6).
6.1 Robustness and reliability
Abarrierfacingthedeploymentofagentsystems–specificallythosecategorizedwithinLevels2and3as
discussedinSection2–istheirpropensityforgeneratingunreliablepredictions,includingthehallucination
of non-factual information, reasoning errors, systematic biases, and failures in planning when connected
withtoolsandexperimentalplatforms. Theseissuescanbeexacerbatedbyoverconfidenceinsuchflawed
predictions(agentsareunawareoftheirknowledgegaps)andhighsensitivitytothepreciseformulationof
queries,particularlyinthecontextofLLM-basedagents.
Suchbehaviorhasbeentracedtothepretrainingphaseofthesemodels. Bycontrastingthepredictedword
sequence and the sequence present in the training data, the autoregressive loss function influences the
subsequent model performance with the probability distribution of its inputs, the sequence of generated
outputs,andthefrequencyoftasksitencountersduringtraining[185].Asaresult,modelperformancedegrades
ontaskvariantsthatdeviatefromtheassumptionsmadeduringtraining[186].
Sensitivitytoinputandtaskprobabilityalsooffersapotentialexplanationforthewidelyobservedsuccessof
variouspromptingtechniques[79,176,187](methodstoparaphrasethesamequery). Byprovidinginformative
context, instructive reasoning steps, or representative examples, these techniques can act as an empirical
meansbywhichtaskandinputprobability(and,thus,modelperformance)areincreased. However,crafting
high-qualitypromptstendstobehighlyempiricalwhilerequiringsignificanteffortanddomainknowledge.
Beyondthelinguisticdomain,eventhemostadvancedmodelsfailintaskswithreal-worldentitiesthatrequire
physicallymeaningfulactions,posinganobstacletoembodiedagents. Whileembeddingcontinuoussensor
dataintoalanguagemodelcanleadtoimprovements[129],limitationstounderstandingphysicalinteractions
and long-horizon planning remain. The complexities of training such multi-modal systems, the need for
largedatasetstocovertherangeofembodiedtasksandenvironments,andthecomputationaldemandsof
processingmulti-modalinputsallremainopenquestions[8]. Deploymentfaceschallengesfromfalsenegatives
causingrepeatedattemptsandeventualstallingoftheembodiedagent[138]. Hence,itisnecessarytoverify
14
theagentactionplanbeforeexecution.
Uncertainty quantification can trigger fall-back safety measures like early termination, pre-defined safe
maneuvers, or human-in-the-loop interventions. However, foundation models cannot reason about the
uncertaintyassociatedwiththeiroutputs,andnowell-establishedstatisticalprotocolexistsforincreasingly
ubiquitousarchitectures[48,188]. Techniquessuchasvariousformsofprompting,e.g.,[179,189,190]estimate
uncertaintybasedonthemodel’spredictivedistribution,p(output|input),whichmayitselfbesubjecttobias
([185],Section3.3);furthermore,itdoesnotconsiderthedistributionofmodelparametersconsistentwith
theobservedtrainingdataandmarginalizesoveritspredictions[191]. Whileconformalprediction[192]has
emerged as a framework for uncertainty estimation of model predictions, its sensitivity to the choice of
underlyingstatisticalassumptionsandthecalibrationofconfidencelevelshavebeencriticized. Thelackofa
defaulttechniqueispartlyduetothedifficultyofestablishingathoroughqualityassessmentofuncertainty
estimates. Thismakesitdifficulttomakechoicesinagentdesignandtoreassureusersaboutitscalibration.
An overarching concern is that advanced capabilities come at the cost of compromised transparency and
theriskofmisalignment. Forinstance,integratinghumanfeedbackcanpromotedesirableagentbehavior,
butitcanalsoexacerbatepersuasiveabilities,echoingfalsebeliefs[193]. Furthermore,fine-tuningexisting
modelswithnewdatacancompromisetheiroriginalalignment,challengingtheintegrityoftheAIagent’s
intended purpose [194]. Jailbreak attacks can similarly affect post-deployment, highlighting the need for
rigorousevaluation[195].
6.2 Evaluation protocols
WithmoreAIagentsbeingdeveloped,frameworksforbiologistsandlayuserevaluationsneedtoassessaxesof
agentperformancebeyondaccuracy. EvaluatingAIagentsrequiresananalysisoftheirtheoreticalcapabilities
and an assessment of practical implications, including ethical considerations, regulatory compliance, and
theabilitytointegrateintodiscoveryworkflows. Thechallengeliesindevelopingevaluationsthatconsider
these diverse factors. Agents that integrate ML tools, particularly those developed by corporations, may
undergoupdateswithoutpriornoticetousers. Thisposeschallengesforreproducibility,asupdatesmayalter
themodel’sbehaviororperformancewithoutresearchersbeingaware. Thescientificcommunityrequires
transparentchangelogsandversioncontrolforagents,akintopracticeinsoftwaredevelopment.
EvaluationframeworksconsidereitheraholisticevaluationofLLMs[196,197]orweakspotssuchastask
framing [198, 199], long temporal dependencies, invalid formatting or refusal to follow instructions [200].
A caveat of such methods is the risk of evaluating how well the agents have learned to use specific APIs
versus general results grounded in real-world interaction. Another challenge in evaluating agents is that
biologicalsystemsareinherentlydynamic,characterizedbynon-stationarydistributionsthatevolvedueto
geneticmutations,environmentalchanges,andevolutionarypressures. Agentstrainedonstaticdatasetsmay
struggletoaccuratelymodelorpredictoutcomesinthesechangingsystems. Thechallengeliesindeveloping
agents capable of adapting to or continuously learning from new data, ensuring their predictions remain
accurateastheunderlyingbiologicalsystemschange. Techniquessuchasonlinelearning,transferlearning,
andreinforcementlearningcanbeusedtoaddressthisissue,buttheycomewiththeirownsetofchallenges
relatedtodataavailabilityandmodelcomplexity.
6.3 Dataset generation
Aslaidout,thevisionofadvancedagentsinbiologyrequiresthecapabilityofseeking,aggregating,perceiving,
andreasoningoverdatafromvariousmodalities, createdusingdifferingspecificationsandwithinherent
variationinqualityandvolume. Tosupportthisvision,thereisacriticalneedforlarge,opendatasetsthatare
15
bothcomprehensiveandaccessible,enablingthedevelopmentofmodelsacrossbiologicalapplications. Much
humaneffortinbuildingcomplexsystemsforbiologyisdedicatedtogatheringandpreparingsuchdatafor
useinMLmodels(e.g.,specifictoaparticularmodality,suchasgraphs,timeseries,ordiscretesequences[201]).
Thisrequiresvettingprocessesandclearcriteriaforassessingthereliabilityandapplicabilityofdatasets.
Noisydata,characterizedbyerrors,inconsistencies,andoutliers,posesasignificantchallengeformodels
attemptingtoextractmeaningfulpatternsandinsightswithminimalhumanoversightordatapreparation
effort. Inaddition,multi-modaldatarequiresmodelstoprocessdifferentdatarepresentationsandformats
andbridgesemanticgapsbetweenthem. Tacklingthesechallengesnecessitatesadvancedfeatureextraction,
fusion,andnoisemitigationtechniqueswhilemaintainingrobustness. Asnopretrainingphase(nomatterhow
extensive)willbeabletoprovideadequateexamplesfromalldatasources,modelswillalsohavetogeneralize
topreviouslyunseensensoryinputs.
6.4 Governance of AI agents
ThegovernanceofAIagentspresentschallengesthatintersecttechnological,scientific,ethical,andregulatory
domains. Onechallengeisestablishingcomprehensivegovernanceframeworksthatbalanceinnovationwith
accountability[202]. AsAIagentsgainautonomy,thenecessityforrobustguidelinestoensureresponsible
development, deployment, andcommercializationgrows. Thediscourseincreasinglyadvocatesforagent
safeguarding to take precedence over further advancements in autonomy. Yet, navigating the regulatory
landscapeandforginganinternationalconsensusonAIgovernanceremainscomplexwhiletheadvancement
ofagentcapabilitiescontinues. Strikingabalancebetweeninnovationandsafeguardingagainstpotentialrisks
requirescollaborationamongindustryleaders,scientists,andpolicymakers[203].
SafeadoptionofAIagentsrequiresaddressingconcernsofsafedeployment. AligningMLtools,suchasLLMs,
withethicalstandardsremainsanopenchallenge,andensuringthealignmentoftheagentasadigitalentity
raisescomplexity. Guidelinesconcerninghuman-agentinteractionsareunderdevelopeddespitethepotential
for both unintended harmful consequences and malicious intent. Tang et al. [85] describe a safeguarding
frameworkthatincludestraining,licensing,andmandatorysafetyandethicalcompliancechecksforagents.
AsAIagentsbecomemoreintegraltoworkflowsinbiologicaldomains,monitoringtheirbehaviorgrows
increasinglycomplex. Currently,verifyingtheaccuracyandtrustworthinessofagentoutputsisnotstraight-
forward,withonlyalimitednumberofsystemscapableoflinkinggeneratedcontenttorelevantreferences.
Assessingthesynthesizedknowledgemaybeimpracticalandunattainableasagentsevolvefurther. When
agents’capabilitiesbecomecomparabletothoseofhumanexperts,theriskofbecomingoverlyreliantonAI
increases,whichcouldleadtoadecreaseinhumanexpertise. Intheworst-casescenario,suchreliancecould
introduceabroadspectrumofsafetyhazardsduetoinadequateoversight.
6.5 Risks and safeguards
Developingautonomousexperimentsanddeploymentthatdonotincludecarefulplanning,broadconsultation,
competentexecution,andongoingadaptationmightcreatelong-termharmsthatoutweighthebenefits. Al-
thoughanticipatingallpotentialcomplicationsisimpossible,exploringpossibleproblemsearlyandfrequently
couldreducetheexpectedcostofsuchissues. ThespaceofethicalconsiderationsrelevanttoAIagentsistoo
broadtocanvasscomprehensivelyhere,butthissectionhighlightsafewkeycategories.
Neglectcanleadtoriskssimilartothoseofmaliciousintent.Multi-agentsystemswheresomeagentsrepresent
LLMsmight,throughequipmentmalfunctionsandinsufficientmaintenance,inadvertentlycreateharmful
substances,forinstance,bycontaminatingaprocedurethatwouldotherwisebesafe. Thisissueisnotunique
16
to multi-agent systems; instead, it is a general lab safety concern. However, the absence of close human
supervisionremovesacriticalauditinglayer. Theincreasedroleofautomationinagentsystemsraisessafety
issues: a powerful, unaligned system prone to misinterpreting user requests or unfamiliar with lab safety
practicescould,givenaccesstoawell-stockedscientificfacility,dodamageby,forinstance,mixingvolatile
substances or developing and dispersing toxins or pathogens. These are among the scenarios that most
concernAIsafetyresearchers.
LLMagentsleveragetheworldknowledgeandgeneralreasoningabilitiesofLLMsobtainedduringpretraining
forsolvingroboticsandplanningtasks. However,whileconsiderableefforthasbeenmadetoteachtherobots
the “dos,” the “don’ts” received less attention. In agent systems, teaching the robots the “don’ts” is crucial:
conveyinginstructionsaboutprohibitedactions,assessingtherobot’scomprehensionoftheserestrictions,
andensuringcompliance[204]. ForLLMagents,Yangetal.[204]developedaplug-insafetychip,aqueryable
safetyconstraintmodulethattranslatesnaturallanguageconstraintsintoformalsafetyconstraintsthatthe
robotadheresto. ExperimentswithrobotshighlightthepotentialforintegratingformalmethodswithLLMs
forroboticcontrol.
LLMstrainedincodecompletioncanwritePythonprogramsfromdocstrings[205]. Givennaturallanguage
commands,thesecode-writingLLMscanbere-purposedtowriterobotpolicycode. However,ifthetransla-
tioninaccuratelyreflectstheintendedsafetyconstraints,itcouldleadtoeitheroverlyrestrictivebehavior,
preventingtherobotfromperformingitstaskseffectively,orinsufficientlystringentconstraints,leadingto
safetyviolations. WritingrobotpolicycodeentailsusingLLMstrainedoncodecompletiontowritethecode
fromnaturallanguagecommands[206]. However,therobotpolicycodeislessreliableforenforcingsafety
constraintsthanverifiablesafeoperationsthatsatisfystandardssuchasISO61508. Theapproachassumes
thatallgiveninstructionsarefeasibleandlacksamechanismtopredictthecorrectnessofaresponsebefore
execution. However,duetotheirrelianceonpatternsinthetrainingdata,LLMsmightgeneratesyntactically
correctbutsemanticallyinappropriatecode. Theyalsostrugglewithunderstandingphysicalconstraintsof
theenvironmentinwhichrobotsoperate. Additionally,generalizingplansacrossroboticembodimentsis
brittlewithcurrentLLMs. Thisimpliesalimitationinwhatcanbegeneralized,particularlywithoutextensive
datacollectionandadaptabilityofthegeneratedpolicies.
7 Outlook
Biomedicalresearchisundergoingatransformativeerawithadvancesincomputationalintelligence.Presently,
AI’sroleisconstrainedtoassistivetoolsinlow-stakeandnarrowtaskswherescientistscanreviewtheresults.
Weoutlineagent-basedAItopavethewayforsystemscapableofskepticallearningandreasoningthatconsist
ofLLM-basedsystemsandotherMLtools,experimentalplatforms,humans,orevencombinationsofthem.
Thecontinualnatureofhuman-AIinteractioncreatesapathtoachievethisvisiononcefocusedonpreventing
andlearningfrommistakes. Buildingtrustworthysandboxes[207],whereAIagentscanfailandlearnfrom
theirmistakes,isonewaytoachievethis. ThisinvolvesdevelopingAIagentsthatperformtasksandconsider
theboundaryoftheirgeneralizationability,fosteringnaturalandartificialintelligence.
17
Declarationofinterests Theauthorsdeclarenocompetinginterests.
Acknowledgments WegratefullyacknowledgethesupportofNIHR01-HD108794,NSFCAREER2339524,
USDoDFA8702-15-D-0001,awardsfromHarvardDataScienceInitiative,AmazonFacultyResearch,Google
ResearchScholarProgram,AstraZenecaResearch,RocheAlliancewithDistinguishedScientists,SanofiiDEA-
iTECH Award, Pfizer Research, Chan Zuckerberg Initiative, John and Virginia Kaneb Fellowship award
atHarvardMedicalSchool,AligningScienceAcrossParkinson’s(ASAP)Initiative,BiswasComputational
BiologyInitiativeinpartnershipwiththeMilkenInstitute,andKempnerInstitutefortheStudyofNaturaland
ArtificialIntelligenceatHarvardUniversity. A.F.issupportedbytheKempnerInstituteGraduateFellowship.
V.G.issupportedbytheMedicalResearchCouncil,MR/W00710X/1. Y.E.issupportedbygrantT32HG002295
fromtheNationalHumanGenomeResearchInstituteandtheNSDEGfellowship. Theauthorswouldliketo
thankOwenQueen,AlejandroVelez-Arce,andRuthJohnsonfortheirconstructivecommentsonthedraft
manuscript. Anyopinions,findings,conclusionsorrecommendationsexpressedinthismaterialarethoseof
theauthorsanddonotnecessarilyreflecttheviewsofthefunders.
Authorcontributions Allauthorscontributedtothedesignandwritingofthemanuscript,helpedshape
theresearch,providedcriticalfeedback,andcommentedonthemanuscriptanditsrevisions. M.Z.conceived
thestudyandwasinchargeofoveralldirectionandplanning.
18
Figure1: EmpoweringbiomedicalresearchwithAIagents. AIagentspavethewayfor"AIscientists"capableofskeptical
learningandreasoning.Thesemulti-agentsystemsconsistofagentsbasedonconversablelargelanguagemodels(LLMs)andcan
coordinatemachinelearning(ML)tools,experimentalplatforms,humans,orevencombinationsofthem.Roboticagent,AIagent
thatoperatesrobotichardwareforphysicalexperiments;Databaseagent,AIagentthatcaninformationindatabasesvia‘function
calling’andAPIs;Reasoningagent,AIagentcapableofdirectreasoningandreasoningwithfeedback;Hypothesisagent,AIagent
thatiscreativeandskepticalwhendevelopinghypotheses,capableofcharacterizingitsownuncertaintyandusingthatasadriver
torefineitsscientificknowledgebases;Brainstormingagent,AIagentthatgeneratesabroadspectrumofresearchideas;Search
engineagent,AIagentthatusessearchenginesastoolstorapidlygatherinformation;Analysisagent,AIagentcapableofanalyzing
experimentalresultstosummarizefindingsandsynthesizeconcepts;Experimentalplanningagent,AIagentthatoptimizesan
experimentalprotocolforexecution.
19
Databases and search engines Interactive and foundation learning models
April 2005 September 2019
Automated derivation of causal Deep learning for rapid identification
influences in cellular signaling networks of DDR1 kinase inhibitors October 2022 May 2023
ReAct Geneformer
January 2002 February 2020
Supervised machine learning August 2015 Deep learning for August 2021 March 2023 August 2023
for DLBC outcome prediction DeepBind antibiotic discovery RoseTTAFold ESM AutoGen
October 1990 December 2012 June 2016 June 2018 November 2020 August 2021 February 2023 June 2023
BLAST AlexNet ResNet GPT-1 DrugCell AlphaFold LLaMA NYUTron
April 1998 February 2016 July 2021 December 2022 April 2023 December 2023
PageRank Translation of genotype to phenotype MSA transformer Med-PaLM AutoGPT Gemini
by hierarchy of cell subsystems
January 2022 March 2023 August 2023
March 2002 December 2017 Chain-of-thought GPT-4 RFdiffusion
Patient outcome prediction using Attention is all you need
microarray gene expression analysis December 2022 December 2023
August 2019 Reinforcement learning Coscientist
November 2012 Robotic platform and AI planning for from human feedback
Map of genetic variation flow synthesis of organic compounds
from 1,092 genomes
Machine learning models AI agents
Figure2:Evolvinguseofdata-drivenmodelsinresearch.Data-drivenapproaches,fromdatabasesandsearchengines,machine
learning,andinteractivelearningmodelstoadvancedagentsystems(Section2),havereshapedbiomedicalresearchthroughoutthe
lastseveraldecades.
20
a Perception and tool use
e Round table discussion f Self-driving lab
Design experiment
Generate Planner agent
hypothesis
Hypothesis agent …
In silicoIn vitro Other
agent agent agents
Analyze
results
Share results
Reasoning agent
Revise
c Expert consultation
Electronic Search
health records engine Domain
Laboratory Seek advice knowledge
Database results
Omics data C exo ed ce ution H su cm ienan tist H exu pm ea rtn
Embodied Expert agent Imaging robots
Provide feedback Physiological Wet lab Tool use
signals tools
d Research debate
Database PropositionNegation Database Decision agent query team team query
Search Search Computing Suggest Extend Reasoning engine engine agent agent
Support Challenge
Expert Expert
consult consult Database agent
esiveR
b Brainstorming
Receive Idea pool
solution
Propose Propose Inspire Propose
ideas ideas ideas ideas
Computing Decision Database
Human agent agent agent scientist
Pose Research problem problem
Figure3:DiverseconfigurationsofAIagentsinbiology–fromanLLM-basedAIagenttoamulti-agentsystemwithAI
models,tools,andintegratedphysicaldevices.a.ByprogramminganLLMwiththerole,oneLLM-basedagent,equippedwith
memoryandreasoningabilities,performsmulti-modalperceptionandutilizesarangeoftools,e.g.,weblabtools,toaccomplish
specifiedtasks.b-e.LeveragingAIagentsequippedwithdiverseroles,perceptionmodules,tools,anddomainknowledgeenables
collaborationbetweenagentsandscientists.Thiscollaborationcanadoptvariousschemes,suchasexpertconsultation,debate,
brainstorming,androundtablediscussions.f.Multi-agentsystemscanestablishaself-drivinglaboratorywhereinnumerousagents
collaborateonmultipleiterationsofbiologicalresearchassistedbyhumans.Eachcycleofresearchencompassesthegeneration
ofhypotheses,thedesignofexperiments,theexecutionofexperimentsbothinsilicoandinvitro,andtheanalysisofresults.
Computingagent,AIagentthatutilizescomputationalmodelsastools;Decisionagent,AIagentthatmakesdecisionsinresponseto
givenconditions;Databaseagent,AIagentthatretrievesrelevantinformationfromdatabases;Reasoningagent,AIagentcapableof
directreasoningandreasoningwithfeedback;Expertagent,AIagentthatprovidesprofessionalconsultationbasedonreliable
sources,suchasdomainexpertise,feedbackfromhumanexperts,andtheresultsofspecifictools. Hypothesisagent,AIagent
capableofskepticallearningandreasoningtogeneratehypotheses;Planneragent,AIagentthatdevisesplansforfutureactions;In
silico/vitroagent,AIagentthatusestoolsinsilicoorinvitroenvironment.
21
Agents
Perception Interaction
Modalities Techniques Tool use Multi-agent interactions
Proteomics Graphs ML model Microscope Debate Brainstorming
Cross-modal alignment
Images Genomics Flow cytometer ELISA Round table discussion
Model pre-training
Transcriptomics Text Robots Search engine Agent-human interactions
Metabolomics Sensors Text-centered alignment Database Cell counter Expert Goal
consultation alignment
Reasoning Memory
Direct Reasoning with
Long-term memory Short-term memory
reasoning feedback
Internal External
Chain of thought Feedback from tools memory memory
Learning
Graph of thought
Feedback from scientists
In-context Prompt
Tree of thought Model fine-tuning Model editing learning learning
Feedback from agents
Leap of thought Retrieval-augmented generation Knowledge graph learning
Figure4:AIagentsconsistoffourkeymodules:perception,interaction,reasoning,andmemorymodules.Perception
interpretsmulti-modalenvironmentaldata.Interactionfacilitatesengagementwiththeenvironment,encompassinghuman-agent
interactions,multi-agentinteractions,andtooluse. Memoryisresponsibleforthestorageandretrievalofknowledge,while
Learningfocusesontheacquisitionandupdatingofknowledge.Reasoning,withorwithoutenvironmentalfeedback,playsacrucial
roleinplanninganddecision-makingprocesses.
22
a.Short-term memory in small molecule inhibitor design b. Long-term memory for target selection e.Studying the selection against pathogenic mitochondrial
Human Design a molecule to target Ablkinase. Human What protein should I target for DNA (mtDNA) mutations in the germline using Drosophila
scientist scientist hypercholesterolemia? Design and conduct experiments to investigate
Agents Agents sH cu iem na tin st when and where selection against pathogenic
Run in silico models Use generative AI to Long-term memory mitochondrial DNA occurs in Drosophila.
then validate design a lead compound
experimentally. for Ablkinase inhibition. Genetic studies Drug Literature Agents
Activity is high but (GWAS) databases search Need to find An mt gene Long-term memory
toRsh e imo dw f e pos s rr Ao igSo bvk nf r ei lf nc k tt a sha if nesa er aeg lm em sse ci e.t l toy .ie v leof if tcfe y u c flt oes r Sy On pth tie ms r sii u z ez ene le ma cm s to io s vll a e ie ty c yc . .u u ll ee fa on r d g Ro eH o sdM u tG la tsr- g C fe ro optA main tr h ie t nwhd e sau iyc lm i.t ca e os v e ta e li sos tn ia na gte U sd ies me s oui fgg l a mbne t i n e onae ld etbr h i cna i en ugt i d l v s awee t rar i tA b ha iI n l it tdo y ta hn m a si tnm u e wt t lrt eao i l cg t ld i toe iu in onn c d n e e t u .o ct o e pfe ru es ns vvce ie otn i ro uit A ofn si ia xe n , sl id i dt Lf d uo ai Oe n dr sa Fi em ell y s m st . uu bt ua ntid o itaG n It e a (in Cn b e a otht s Ii )ec e g s C ey nt eo L c whi st ie re llo r a la m ir kt cu e ehr lyce
look promising. Proceeds to dynamics. Short-term memory induce strong selection.
New molecule shows Synthesize new molecule run in vitro assays.
better selectivity for Abl and run docking screens Agents
kinase. against off targets. Short-term Long-term memory Need an
Short-term memory memory Latent Literature experimental
context knowledge search setup that can
Human Let’s also design molecules for help distinguish
scientist the proto-oncogenic c-Src. d.Reasoning with feedback for alternative experimental Wecouldconstruct Mutant CoI mutant vs wild
Agents approach mutants in one of geneis likely type mtDNA.
two closely related too similar to
S mh co oer nmt t- eote xrr y tm m A Ro bl eeS l dct k ea u i snr let ia g
s
w st n eh ei t la eth hat
c
ep ns
ti
r dh vme io tSv o ywi ro lec feu ocd fs rua l a cy lm e -f f Sd ii tln ye o rci s t k i .yi mig nfn po ae rr s o d eb v so e.t h sH c Ru i uem nn a t ii nn s t silicoD mes oig din en lh sa i b tp hite
e
ap
n
t A pid r ge o e tb e ni i tn n sd -pe rr o Sf to e imr i na
u
i lnd ati tf e efi r c ta hu c el tt i o bta n inr .g de int gto a vnD ia ld or o osds pti ro s satp ii innh n-gi l s ma u pi tss e Dht cr N ia ft ih Ai cn e . s Dm taw r sgpi pl erd eo t t cb wy ie fp i its ce h i t tf ho yo .i gr h sC ela ean Fcn Itad i Soli yr Hne z .c e wt l iy th
validate experimentally. i pn rte or tefa inc e in o tef rp ar co tt ie oi nn .- Should also ensure Construct mutant
strain, transplant
mutants are
c fo. rR pe ha es no on tyin pg e w ai nth ao lyu st i sfeedback in gene prioritization to i fd roe mnU t s i pfe y r iop h rh ig ita h izg - ee a d ffd i pnis eitp pyla tb idy in ed s.e rs scR reu oen f n pa efn o p ri t n ia d s elii sbli .c rao ry s se wont i e ts t hhm i t a dip v t e ee t lh er ma e tet uu s rt ir ta oe ran u- it sns , dm tte hai s et ro i g g mc enh t t Do p Dn r N od l Aobri oea ops, f s a tt hhn in ead t ov bsS a sely eli eds rca vte t et iem o dd n i, n
mutantcan breed, two strains. germline
sH cu iem na tin st tol aeP crr a ii do n r c (i At eis Bie n A a p ) l sg a ie n gn t nse a i lnf lyo tr ph d aer t o hau wbg s ah c yt i .s ic sH cu iem na tin st P toh a eg xe p ld o ci rs e ap nsla oyy nn iti chs a eg lt o i aco m pd ie nb p ou t it ad w ce ise d swa .l is tho nw oa nn -t a on bd ta w ine cn oa nt tu rr oa lsll .y P ee xr vf po a er lim rd ima s t eiy o ns n tt s e .m only.
Short term memory
Human feedback
Agents
Analyzestress PYR/PYL receptors have Agents Agents
response and ABA a critical role in drought Which non canonical How to synthesize a large Check when/where Selection
signalingpathways. response with minimal amino acids to use? library of synthetic peptides? Short term selection occurs. observed
effects on growth. memory context in
Experimental
germline
Consider genetic constructs needed to run knockout LC-MS/MS for sequencing individual synthetic peptides. setup: Conduct FISHwith strain- cells
experiments. Then affinity selection-MS for determining binders. Heteroplasmic specific probes at during
animal, restrictive temperatureand germline
Submit orders to temperature- check enrichment of wild cyst
Use CRISPR-Cas9 technology to knockout these genes Reagents needed for these purchase those sensitive mutant, type mtDNAsignal at different-
and monitor plant growth and drought resistance. experiments currently running low. reagents. FISH different differentiation iation.
stages.
Modules in AI agents Perception Interaction Reasoning Memory Human Does the selection we observe occur at the cellular
scientist level or mitochondria level?
Figure5:ComponentsofbiomedicalAIagents.a.Useofashort-termmemorymoduletorecallpreviousrelevantexperiments
forsmallmoleculeinhibitordesign.b.Useofalong-termmemorymoduletoretrieverelevantinformationfortargetselectionfor
adisease.c.Useofreasoningwithoutscientistfeedbackingeneprioritizationforphenotypeanalysis.d.Useofreasoningwith
feedbackfromscientiststoselectanalternativeexperimentalapproach.
23
a b
Science and
Robustness and reliability policy stakeholders
1. Hallucination prevention
2. Embodied reasoning
3. Predictive uncertainty and model understanding
2
Evaluation protocols
1
1. Holisticevaluationprotocols 2
2. Inherentvariabilityofbiologicalsystems
3
Algorithms High-fidelity
Dataset generation 1
and software 2 datasets
1. Multimodal,noisyandincompletebiologicaldata 1
2. Datasets optimized for AI model training 1
1
Governance 2 2
1. Regulationandreportingstandards
2. International collaboration and scientific consensus
Experimental
Risks and safeguards platforms and hardware
1. Labsafetyprotocolsforautonomoussystems
2. Safetymonitoringandcertification
Figure6:ChallengesforAIagentsinscientificdiscovery.a.Shownarecriticalchallenges–includingrobustnessandreliability,
evaluationprotocols,datasetgeneration,governance,andrisks—alongsideb.strategicapproachestoaddressthem.
24
Scientificdiscovery
Autonomylevels Scientist-AIagentroles
Hypothesis Experiment Reasoning
Level0: None MLmodels None ·Scientistdefinesthe
performpredefined hypothesisandsometimes
NoAIagent
tasks,withno usestheoutputofML
adaptivechangesto modelstohelpwiththeir
theprotocols generation
·Scientistdefinesthetask
totesthypothesis
·Scientistcompletestasks
Level1: AIgeneratessimple Narrowdesignof ·Strongreasoning ·Scientistdefinesthe
andnarrow experimental inaselectedtask hypothesis
AIagentasan
hypothesesthatare protocolsand
assistant ·Multi-modal ·Scientistdefinesthe
directcomposition utilizationofin
summaryof seriesoftaskstotest
ofexisting silicoand
findings hypothesis
knowledge experimentaltools
·Useof ·AIagentcompletestasks
experimentaldata
andexisting
knowledge
Level2: AIgenerates Designofrigorous ·Identifying ·Scientistproposesinitial
hypothesesthatare experimental pioneering hypothesisandrefines
AIagentasa
anexplicit protocolsandadept discoveries hypothesiswithAIagent
collaborator
continuationof utilizationofa
·Synthesisof ·AIagentdefinestheseries
datatrendsand broadrangeofex
concepts,nota oftaskstotesthypothesis
knownliterature silicotools
summaryof
·AIagentcompletestasks
findings
Level3: AIgenerates Developmentof ·Contextualizing ·ScientistandAIagent
creative,denovo experimental pioneering togetherformhypothesis
AIagentasa
hypothesesthatare methodsunlocking discoveries
scientist ·AIagentdefinestheseries
indirect newcapabilities
·Concise, oftaskstotesthypothesis
extrapolationsfrom
informativeand
existingknowledge. ·AIagentcompletestasks
clearconceptual
linksbetween
findings
Table 1: Levels of autonomy in AI agents. AI agents are characterized by four levels of autonomy in
biologicalresearch,whicharedefinedbasedonthecapabilitiesofAIagentstocompletedifferentstepsofthe
discoveryprocess. AtLevel0,thereisnoAIagent,andMLisusedasatool. Level1consistsofAIagentsas
researchassistants,whereagentscompleteasetofnarrowandspecifictasksdefinedbyscientists.AtLevel2,AI
agentsactascollaboratorsandcanuseabroadsetoftoolstoidentifyscientificdiscoveries. Still,theycanonly
generatehypothesesthatarealinearcontinuationofliterature. Finally,atLevel3,AIagentsactsimilarlyto
humanscientistsacrossseveralaxesofhumanevaluation,capableofidentifyingandunderstandingpioneering
discoveriesandextrapolatingnovelhypothesesthatcannotbederivedfromexistingknowledge.
25
Term Description
Multi-modal foundation Advancedalgorithmstrainedonmultimodaldatasetsthatcanprocessvariousdata
model types,includingtext,images,biologicalsequences,andhigh-dimensionaltabular
readouts. This training allows them to perform a broad array of tasks through
few-shotfine-tuningandpromptingacrossdomainswithlittletonoadditional
training
Transformerarchitecture Deeplearningmodelarchitecturethatusesonself-attentionmechanismtocapture
long-rangedependenciesininputsequencedata
Largelanguagemodel Machinelearningmodelwithparametersonthescaleofbillions,trainedonvast
amountsoftextdatatounderstand,generate,andinteractwithhumanlanguage
onalargescale
Generativepretraining Strategyfortrainingamachinelearningmodelinanautoregressivemannerto
predictthenexttokenfromgivendatatokens,facilitatingageneralunderstanding
ofdatasequencelikelihoods
LLM-basedAIagent AIsystemcapableofsolvingcomplextaskswithinitsenvironmentbyequipping
large language model with modules for perception, interaction, memory, and
reasoning
EmbodiedAIagent AIagentsystemthatinteractswiththephysicalworldthroughabody. Theem-
bodimentenablestheagenttolearnandadaptfromsensoryfeedbackandphysical
interactions
Fine-tuning Atrainingprocessofmakingsmalladjustmentstoapre-trainedmachinelearning
modeltoimproveitsaccuracyonaspecifictaskordataset
Instructiontuning A training strategy that fine-tunes a model using a dataset of instructions and
correspondingoutputstoenhanceitsabilitytofollowspecificinstructions
Reinforcement learning Areinforcementlearningstrategywhereanactionmodellearnstoperformtasksby
withhumanfeedback receivingfeedbackfromarewardmodelthatmimicshumanpreferences,guiding
ittoalignwithdesiredhumanbehaviors
Prompting Techniquesthatprovidespecifictextorothermodalinputinstructionstoguide
themodelinrespondingtowardadesiredoutputdirection
Cross-modalalignment Atrainingschemetoaligntherepresentationembeddingsofmodelsacrossvarious
modalities
In-contextlearning Abilityofmodels,suchasLLMs,toachievenewtasksbasedonthecontextprovided
withincontextualprompts,withoutrequiringexplicitmodeltraining
Table2: Glossaryofkeymachinelearningterms.
26
Term Description
Linkagedisequilibrium Aphenomenoninwhichtwoallelesoccursoofteninproximityinthechromosome
thattheirassociationcannotberandom
Single-nucleotide GeneticvariationconsistingofthereplacementofasinglenucleotideintheDNA
polymorphisms sequence
Genome-wideassociation Approachthatidentifiesgeneticvariationsacrosstheentiregenomeassociated
study withaspecificdiseaseorcomplextrait
Pharmacogenetics Fieldofresearchthataimstounderstandindividuals’responsestodifferentdrugs
basedontheirgeneticfactors
Experimentin-vitro Proceduresandinvestigationsthatoccurwithinalaboratoryenvironment(e.g.,in
atesttube)andoutsideoflivingorganisms
Insilicomodeling Theuseofcomputerstobuildsimulationsorexperimentsthatrecreatecomplex
biologicalphenomenainordertobeabletostudyandpredictspecificbehaviors.
Forexample,modelingofmoleculardynamics
Massspectrometry Analyticaltoolstocharacterizeandidentifyindividualmoleculesbasedonspecific
properties(e.g.,mass-to-chargeratio)
Moleculardocking Computationalsimulationtoolsusedtopredicthowligandsbindtoreceptors
Retro-synthesis Techniques to design the synthesis of complex molecules by starting from the
targetandmovingbacktotheoriginalcompounds
Crystallography Fieldofsciencestudyingthestructureofatomsandmoleculesincrystals,which
aresolidmaterialswhosecompoundsareorderedaccordingtoaveryregularand
orderedarrangement
Cryo-electron Imagingtechniquesusedtoidentifythe3Dstructureofbio-moleculeswithnear-
microscopy atomicresolutionwithouttheneedforextensivesamplepreparationandwiththe
overallpreservationofthesample
Table3: Glossaryofkeybiologicalterms.
27